# Connection and SSL

## DNS Lookups

Most engineers don't consider DNS lookups when they are optimizing their page's load time for a few reasons:

1. During development, you probably aren't connecting to a remote server.
2. If you are connecting to a remote server, your browser or operating system probably has the DNS lookup cached.
3. Most developers are on relatively low-latency connections and DNS lookups are fast.
4. There isn't much you can do to speed the DNS lookup up.

To demonstrate the performance impact of a DNS lookup, consider the following waterfall diagram of a website:

![Waterfall diagram of the Firefox Marketplace, taken from WebPageTest](images/dns_waterfall.png)

You can see in this diagram that it took 111ms before the browser could even begin to connect to the CDN and perform an SSL handshake. If your goal is to make a page load in under one second, 100ms is not something you have to spare.

DNS lookups should be considered slow by default, and they play a very large role in decreasing the performance of websites. To illustrate, here's a graph generated by the open source application namebench:

![Distribution of DNS response times (pulling up and left is better)](images/dns_namebench_responses.png)

This benchmark was run from my apartment in Mountain View, California over wifi. My ISP is Comcast, and the results support that: the two lines furthest to the left are Comcast's DNS server (75.75.75.75) and my wireless router (which uses Comcast's DNS)[^google_dns_throttle]. Curiously, Comcast's alternate DNS server (75.75.75.76) is among the slowest, taking a minimum of 40ms for its fastest response.

[^google_dns_throttle]: It should be noted that the results for Google's DNS servers shift sharply to the right, indicating that their servers may have throttled connections from my IP address during the test, resulting in unusually high lookup times.

My internet connection is average, or perhaps slightly above average compared to the rest of the continental US. Based on this benchmark, however, you can see that DNS lookups took--regardless of the DNS server--a minimum of about 15ms for the absolute fastest responses. The 80th percentile (one out of every five), though, took longer than 60ms. At the 90th percentile, lookup times nearly triple to well over 150ms.

### Remedying slow DNS lookups

There's very little you can do to make DNS lookups faster, but you can do a number of things to decrease their impact.

The first solution is to use a single domain name. If you don't need separate subdomains, don't use them. The more domains in your application, the more DNS lookups that will need to be performed, and removing all but one ensures that your page load time is not impacted more than once.

Unfortunately, using a single domain is rarely an option for many websites. To use CDNs or take advantage of domain sharding (both discussed later), it's often necessary to have--at minimum--a second subdomain.

In this case, the second best option is to give the browser a hint about where your content is hosted before you request it. This is very easy: simply drop the following `<link>` tag on your page for each domain your site accesses:

```html
<link rel="dns-prefetch" href="//your.other.domain.com">
```

The browser will use that information to immediately start a DNS lookup of the hostname specified. If a request is made where the hostname matches the domain in the `href=""`, the corresponding address will already be cached.

This even works if you send HTML to the browser incrementally (e.g.: using PHP's `flush()` function). The browser will kick off the DNS lookup immediately, and resources sent to the browser later as part of the same page will use the cached response.

Lastly, if you are taking advantage of domain sharding, it's likely that you're imposing a very large number of DNS lookups on the client. For instance, a site using domain sharding might make the following requests:

```
www.mysite.com
static1.mysite.com
static2.mysite.com
static3.mysite.com
```

At more than 100ms each, the volume of DNS lookups can quickly dominate a large part of your page's lifecycle. You can mitigate this issue by implementing SPDY on your server. Domain sharding is used to circumvent caps specified by the browser to limit the number of connections to any one host. SPDY combines an unlimited number of concurrent requests into a single connection, meaning users with modern browsers accessing sites that support SPDY will only perform a single DNS lookup. This solution obviously has all of the downsides of implementing SPDY, which are outlined in the section dedicated to SPDY.

## TCP Connections

Like DNS, the actual TCP connections involved in each request are an often-overlooked component in web performance and a piece which has few remedies. TCP connections are inherently expensive: connecting and disconnecting each involve one and a half round trips. Most browsers limit the number of connections that can be made to any given host. There are a number of signals that you can look for, though, that can indicate a potential performance bottleneck.


### Too many connections

Until recently, browsers limited the number of HTTP connections to any single host to 2. Most modern browsers have increased that limit to at least 6[^ie_connection_limit]. This number is usually sufficient for relatively small pages with only a small number of assets, but it can be disastrous for content-heavy pages that make dozens of requests.

[^ie_connection_limit]: Internet Explorer 10 and up and Opera 10 have a limit of eight concurrent connections rather than six.

![TCP connections made to a single host](images/tcp_limit_waterfall.png)

The above is a screenshot from the Chrome developer tools showing a series of requests for images. I've drawn in red lines to show that the end of one request triggers the start of another. Also notice that no more than six requests are triggered concurrently at any given time.

The first way to remedy this is to make sure that if you can, SPDY is implemented on the server. SPDY allows an unlimited number of concurrent connections, and the server can decide how it wants to respond to them depending on load.

The second solution to this is to simply decrease the number of requests. Even with SPDY, the more requests that are made, the longer it takes to load the page for the simple reason that there's more things to do. If multiple files can be combined with no impact on the user, that is a worthwhile change to make. Later chapters discuss in more detail how to effectively combine assets.

Lastly, you can use a technique known as domain sharding. Domain sharding (as described previously with regard to DNS lookups) involves creating several DNS records for the same host. For instance, `static1.example.com`, `static2.example.com`, etc. might all point at the same IP address. In the document, the URLs for each asset are changed to point at a different subdomain. In doing this, the browser recognizes each hostname as its own server and applies the six connection cap to each hostname. If you use `static1` through `static4`, you would expect to be able to six connections to each host concurrently, allowing up to 24 simultaneous connections.

As mentioned previously, domain sharding comes at a cost: DNS lookups. Despite each hostname pointing at the same IP address, the browser does not know that until after it has performed a DNS lookup.

Previously, a `Connection: Keep-Alive` header could be sent to any client that sent the header as part of the HTTP request headers, allowing the client to re-use connections. Virtually every browser in existence today supports HTTP 1.1, though, where `Keep-Alive` is the default behavior.


### High latency

For users on high-latency connections, creating many TCP connections may be impractical. Other users may have artificially restrictive limits on TCP connections (such as users communicating through an HTTP proxy). In this case, the best solution is to simply decrease the amount of time it takes to establish a connection.

To do this, collect some data. Measure the amount of time it takes to establish a connection to the web server from a point very near to the server (i.e.: from another server in the same data center). If that number is high, you should investigate the stack that you're using on the server. If you don't have a load balancer, or are using a single-threaded server, simply installing a reverse proxy like Nginx may solve much of the problem.

For users that are located internationally, long connection times may simply be a result of distance. Consider using a CDN to serve assets: a CDN can be globally distributed to decrease the physical distance that must be traversed and number of digital bottlenecks that a connection must overcome in order to reach the server.


## SSL

SSL is a misused term: the actual SSL protocol was deprecated many years ago and was replaced with TLS, or Transport Layer Security. Few internet users, however, have ever heard the term TLS, and certificates are still sold to site owners as "SSL certificates" in many cases.

One of the biggest web performance myths in existence is that HTTPS is slow because all of the information transferred must be encrypted. This is false. The overhead of secure connections is so incredibly low that most site owners will never notice it.

The primary bottleneck involving HTTPS is the number of round trips that are necessary to establish a connection. Two full round trips are necessary as part of a "handshake" to exchange cryptographic key information before the client can even begin to make a request.

One half of the solution to the number of handshakes that need to be performed is to simply decrease the number of requests (discussed in the previous section). The fewer connections that need to be made, the fewer times you need to pay the penalty of the handshake.

Having a CDN can also help immensely. A CDN with a local point of presence (PoP) near to the user decreases the amount of time it takes to actually perform the handshake. Additionally, some CDNs or network service providers will offer HTTPS termination services that allow you to terminate the HTTPS connection to the user in a local PoP rather than in a data center far away. This means that you can take advantage of the speed gains that your assets would otherwise receive on your server.

It is possible to create your own termination proxy using open source software like Nginx in combination with a geographic DNS service, though the effort and costs involved are often greater than the benefits.

There are some secondary changes that you can make to improve HTTPS performance:

- **Use secure but fast ciphers.** The most secure ciphers that are employed are oftentimes overkill for most websites and are much slower than some of their good-enough-but-less-secure counterparts. The configurations provided in the sections on setting up HTTPS contain ideal cipher lists.
- **Cache credentials.** If the credentials for a client are cached, quite a bit of the connection process can be skipped. This is done with the `SSLSessionCache` and `SSLSessionCacheTimeout` directives in Apache and `ssl_session_cache` and ssl_session_timeout` directives in Nginx.
- **Enable stapling.** OCSP stapling is a technique that is used to send information about the certificate chain for a site along with the site's key info during the connection process. By "stapling" this data, the browser may be able to skip a few extra steps to check to see whether the site's certificate has been revoked. This may or may not provide much benefit, or may even decrease performance.[^stapling_benefit] You should test whether OCSP stapling improves page load times for your users.

[^stapling_benefit]: OCSP stapling may not provide much benefit if the browser does not perform an OCSP request for the site. If an OCSP check would not have otherwise been performed, the overhead from stapling may overflow the TCP window and create additional packets.


### Setting up HTTPS on your site

Despite the downsides to running HTTPS on your website, it's usually always better to have HTTPS than to not have it. SPDY, for instance, only works when HTTPS is enabled.

The first step to setting up HTTPS is obtaining a certificate. Depending on what you're looking to accomplish by setting up HTTPS, you may require a different type of certificate.

Here are some of the most common types:

Single Domain Certificate
: This type of certificate is good for a single hostname only.

Multi-Domain Certificate
: These certificates--also known as Subject Alternative Name certificates--cover up to 100 domain names. For instance, one of these certificates may cover `example.com`, `anotherexample.com`, etc. These certificates tend to be quite expensive.

Wildcard Certificate
: A wildcard certificate covers a domain (like `example.com`) and all of the subdomains (like `www.example.com` and `mail.example.com`). A wildcard certificate is valid for an unlimited number of subdomains. These certificates can be quite expensive and usually require the purchaser to agree to certain terms.


There are also a number of types of validation for certificates:

Domain Validated Certificate
: A domain validated certificate is a certificate that is issued for a single domain which is validated by the certificate issuer. These are easy to obtain and are usually inexpensive, and the process of obtaining one is usually done automatically.

Organization Validated Certificates
: These certificates display information about the certificate holder in modern browsers. Websites that are looking to provide HTTPS for identity rather than just encryption should consider this type of certificate. This process requires a more thorough validation process than the Domain Validated Certificates that involves a human verification step. Acquiring one of these certificates can take a few days.

Extended Validation Certificate
: This type of certificate is much more expensive and involves a very thorough validation process by the issuer, usually involving phone calls to the owner of the domain, requesting the domain owner add DNS records, adding an HTML tag to the site on the domain, perform certain kinds of background checks, or other verification techniques. Purchasers may be required that they have the rights to use the domain name that the certificate is being issued for. "EV" certificates turn the browser address bar green or show a green chiclet in modern browsers.

Self-Signed Certificates
: These certificates are free and can be created by anyone, however because the certificate is not issued by an authority, users accessing sites with self-signed certificates will receive a very scary warning. You don't want one of these for your site.


If you're using shared hosting or some other sort of managed host (i.e.: you don't manage your own server or the software running on it), the company that hosts your website should automatically start using the certificate if you purchased it from them, or should have some mechanism for adding the certificate to your site via a control panel.

If you manage your own host, you're probably using Nginx or Apache to serve your website. After you've purchased and downloaded your certificate, the first thing you're going to want to do is place your certificate and key files (I'll call them `example.com.pem` and `example.com.key` respectively) in a known location on your server. This is generally the `/etc/ssl` directory. If you received a `.cert` file instead of a `.pem` file, simply change the extension to `.pem`.

I> If you're using IIS, refer to the documentation on the IIS website (http://www.iis.net/learn/manage/configuring-security/how-to-set-up-ssl-on-iis) for instructions.

```bash
# Make the directories if they do not exist.
mkdir -p /etc/ssl/certs /etc/ssl/private

# Move the key and the cert to their proper locations.
mv example.com.pem /etc/ssl/certs
mv example.com.key /etc/ssl/private
```


#### Apache

If you're using Apache, first make sure that mod_ssl is installed. You can do that by running the following:

```bash
# Install the mod_ssl extension
sudo a2enmod ssl
```

Next, update your site's `VirtualHost` to look something like the following:

```apache
# This loads the mod_ssl module
LoadModule ssl_module modules/mod_ssl.so

# Use SSL stapling (available on Apache 2.4+)
SSLUseStapling on
SSLStaplingResponderTimeout 5
SSLStaplingReturnResponderErrors off
SSLStaplingCache shmcb:/var/run/ocsp(128000)

# Redirect all non-HTTPS users to HTTPS
Listen 80
<VirtualHost *:80>
    ServerName example.com
    Redirect permanent / https://example.com/
</VirtualHost>


Listen 443  # HTTPS runs on port 443
<VirtualHost *:443>
    ServerName example.com

    # Make sure SSL is enabled
    SSLEngine on

    # Point mod_ssl at the certificate files
    SSLCertificateFile /etc/ssl/certs/example.com.pem
    SSLCertificateKeyFile /etc/ssl/private/example.com.key

    # Tell mod_ssl to use fast but secure ciphers only
    SSLCipherSuite ECDH+AESGCM:ECDH+AES256:ECDH+AES128:DH+3DES:!ADH:!AECDH:!MD5
    # We want to use "good enough" ciphers instead of the strongest
    # ciphers where possible.
    SSLHonorCipherOrder on

    # Cache client credentials to improve performance
    SSLSessionCache shm:/usr/local/apache/logs/ssl_gcache_data(512000)
    SSLSessionCacheTimeout 600

    # Tell the client to always use HTTPS
    Header add Strict-Transport-Security "max-age=15768000"


    # Put your original Apache VirtualHost configuration here.

</VirtualHost>
```

Note that some authorities may require you to additionally add a `SSLCertificateChainFile` directive to your `VirtualHost`. If this is the case, the CA will make you aware of it and should provide the necessary file(s) and instructions on how to add this extra data.

After you've saved your configuration file, simply restart Apache.

```bash
service apache2 restart
```


#### Nginx

In your `nginx.conf` file (usually found in `/usr/local/nginx/conf/`), you'll find something like this:

```nginx

# ... snip ...

http {
    # ... snip ...

    server {
        listen       80;
        server_name  example.com;

        # ... snip ...
    }

    # ... snip ...

}
```

You should update the configuration to look like the following:

```nginx

# ... snip ...

http {
    # ... snip ...

    server {
        listen       80;
        server_name  example.com;

        # Redirect HTTP users to HTTPS
        return 301 https://example.com;
    }

    server {
        listen               443 ssl;
        server_name          example.com;

        # Point Nginx at the certificate files
        ssl_certificate      /etc/ssl/certs/example.com.pem;
        ssl_certificate_key  /etc/ssl/private/example.com.key;

        # Allow Nginx to use an SSL session cache
        ssl_session_cache    shared:SSL:20m;
        ssl_session_timeout  10m;

        # Some SSL configuration to only allow secure protocols and
        # ciphers. If you require IE6 support, add "SSLv3" to this list.
        ssl_protocols        TLSv1 TLSv1.1 TLSv1.2;
        ssl_ciphers ECDH+AESGCM:ECDH+AES256:ECDH+AES128:DH+3DES:!ADH:!AECDH:!MD5;
        ssl_prefer_server_ciphers  on;
        keepalive_timeout    70;

        # Tell the browser that we always want the user to connect via
        # HTTPS to this site.
        add_header Strict-Transport-Security "max-age=31536000";

        # Enable OCSP stapling
        ssl_stapling on;
        resolver 8.8.8.8 8.8.4.4 valid=300s;  # DNS servers to reference
        resolver_timeout 5s;

        # At this point, include your previous Nginx configuration,
        # such as `location` directives.

        location / {  # Example location directive
            root    /var/www;
            index   index.html index.htm;
        }
    }

    # ... snip ...

}
```

Finally, restart Nginx:

```bash
service nginx restart

# If the above does not work, try
nginx -s reload
# or
/usr/local/nginx/sbin/nginx -s reload
```

Note that Nginx also supports verifying the OCSP responses against a local copy of the issuer, root, and intermediate certificates. This is beneficial to enable, but can be tricky to set up. See the Nginx documentation for more information[^nginx_ocsp_verify].

[^nginx_ocsp_verify]: http://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_stapling_verify


## CDNs

A CDN, or Content Delivery Networks, can do a lot to help speed up a website. Most CDNs offer a plethora of services:

Local Points of Presence (PoPs)
: Servers that are geographically close to users in a particular region. These servers allow users to connect with much lower latency than if they had been connecting over a much larger distance. Strategic positioning of PoPs allows a CDN to minimize the number of network "hops" a client needs to make to interact with the server.

SSL Termination
: By terminating SSL (or performing the SSL handshake) closer to the user, connections can be established much more quickly, allowing the client to make requests faster than they otherwise could.

DoS Protection
: Many CDNs market DoS (denial of service) attack prevention. By sitting between users and web servers, the CDN can be better prepared to accept a flood of requests from an attacker, or to block the flow of traffic from compromised users.

Full-Blown Features
: It's usually the case that CDNs are quick to implement performance-improving features and cutting-edge technology for content delivery. This includes technology like SPDY, IPV6, and low-level connection tuning.


### How does a CDN work?

Setting up a CDN is usually very simple to do. Virtually all CDNs operate as proxies that mirror the content from another site. For instance, you might set up `cdn1.example.com` to point at a CDN mirroring `www.example.com`. When `https://cdn1.example.com/asset/include.js` is requested, the CDN would fetch `https://www.example.com/asset/include.js` and cache it. All users requesting that URL from that point on would fetch the cached version of `include.js`.

>A Note that changing content once it has been cached by a CDN is not always possible. To modify the content, you must access it with a different name.
>A
>A For example, you might reference `https://cdn1.example.com/asset/include.js?20140101` to refer to a version of the file that was updated on January 1, 2014. Every time the file changes, you would update the query string to refer to a URL for the updated version. Using hashes instead of dates or times is also common.

Most CDNs accomplish this mirroring via DNS. Some CDNs, such as CloudFlare, will ask you to change the nameservers for your domain to point at their own nameservers. In doing this, they are able to automatically set the addresses for each of your hostnames to the addresses of their own PoP servers. Other CDNs, like EdgeCast, will give you hostnames to add as CNAME records in your own DNS manager.

Another type of CDN, like Amazon CloudFront, allows you to upload files to some sort of storage. You are then provided with a hostname that you can point users at directly, or point a CNAME record at. Depending on your use case, this may be more or less convenient.


### Pitfalls

One of the most perplexing issues than many people encounter when evaluating a CDN is that they see *slower* responses than accessing their content directly. This is usually the case when only a small number of users are accessing a site with a CDN, especially if the users are distributed around the world.

The cause is that the CDN simply hasn't seen the files that the user is requesting yet. If you request a file from a CDN and the CDN doesn't have a copy of the file, it needs to pause the request, visit your server, wait for a response, then forward it on to the user. Until all of the servers in all of the applicable data centers at your CDN have seen all of your files, you'll notice some poor response times.

Another common pitfall is a CDN over-selling its service. When you use a CDN, your content is hosted on the same servers that host content for thousands of the CDN's other customers. If one of the CDN's other customers is experiencing a DoS attack, the speed of your website could be negatively impacted. Be sure to thoroughly research all of your options before you commit to any CDN.

> Snake oil makes you feel great until you need to hit the commode

Cost can be another pitfall with a CDN. Before choosing a CDN, model your expected costs based on your own data. Consider how much it will cost to be a customer with historical data, and also project figures accounting for future growth. Also be sure to compare this with the cost of bandwidth on your current host (if any) to account for potential savings. On some platforms, like Linode or Microsoft Azure, large amounts of bandwidth can be far more expensive than using a CDN to transfer the same content.


### The myth of the P2P CDN

A technology that took the internet by storm in recent years has been the (alleged) peer-to-peer CDN. The concept uses WebRTC: a very new web technology that allows browsers to communicate with each other directly. Content is (allegedly) transmitted from the original host or a traditional CDN to one or more clients, and those clients then distribute the content to other clients that visit the page.

On paper, this idea is phenomenal. In practice, this is almost entirely useless for serving anything other than very large files, like videos or music.

- You need to have multiple concurrent users visiting the same site with the same set of assets.
- You need to deliver a rather large script to each user to allow the clients to be able to establish the P2P connection and communicate effectively. By the time such a script was sent, your page could have been mostly loaded.
- Connecting the users to each other isn't instantaneous (or guaranteed to work 100% of the time), and that doesn't account for the time required for peers to advertise which pieces of the content they have or can provide.
- An attacker could pretend to be another client visiting your site and simply send garbage to legitimate visitors. Even if the clients perform checksums on the data and throw out the garbage, an attacker could potentially lay waste to the performance of a site, or bring it down entirely.
- Users often have slow upload speeds.
- Users on mobile connections suffer significantly: downloads become fragmented over multiple connections which has a significant penalty, and mobile users that are tasked--perhaps erroneously--with uploading waste significant bandwidth.

It's unlikely that P2P CDNs are going to become a viable technology for most websites to take advantage of for quite a long time. In testing out various P2P CDNs for myself, I discovered that most can't even make their own demos function properly due to a lack of users accessing their website.


## SPDY

SPDY is a very new and very powerful tool developed by Google for improving web performance. It functions as a substitute for HTTP at the protocol level: requests are sent in a way that's very similar to traditional HTTP, and applications running on the web server are generally not even aware that the requests they are receiving were made over SPDY. In fact, neither the Chrome nor the Firefox developer tools distinguish requests made by SPDY from requests made over normal HTTP.

In general, there are virtually no downsides to using SPDY over HTTP.


### How does it work?

When a browser connects to a server and establishes a secure connection, the remote server uses a TLS extension known as *Next Protocol Negotiation* to signal to the client that it will use SPDY if the client is okay to use it. If the client can accept SPDY, the SPDY connection is established.

Once the connection has been established, the client will make as many requests as it needs over the same connection. The server will then respond with each of the files multiplexed over the same connection. Each of the requests and responses compresses the headers using Gzip or DEFLATE. If the server can predict what the client is going to do next, it can preemptively send assets to the client before they have been requested.

- Single connection means one SSL handshake
- Compressed headers means far less information is sent over the wire (in both directions)
- Low overhead for requests means minified files don't need to be concatenated: they can be requested individually, improving caching and decreasing waste from downloading unnecessary files
- No need for domain sharding (in fact, domain sharding hurts SPDY)
- SPDY connections stay open, preventing future requests from needing to open a new socket

Results posted in Google's SPDY whitepaper[^spdy_whitepaper] show speedups of 25% to 60%, though in practice improvements of 5% to 15% can be expected[^spdy_improvement].

[^spdy_whitepaper]: http://www.chromium.org/spdy/spdy-whitepaper
[^spdy_improvement]: From *A comparison of SPDY and HTTP performance* by Microsoft Research, and my own experience


### Good god that's fast

You're not kidding.


### Which users benefit

All users are going to benefit from SPDY, but different users will benefit in different ways.

- **10th percentile users:** Users that already have very fast connections will see minor improvements in areas where large numbers of requests are being made. Improvements will also be seen when making subsequent requests, as a new connection and handshake don't need to be made.
- **50th percentile users:** These users will see a substantial benefit from the decreased need to make many connections to request many assets. As soon as the SPDY connection opens, the browser can make unlimited requests, not just one.
- **90th percentile users:** These users will see all of the benefits seen by the other users. Additionally, the 90th percentile will benefit from header compression. Headers are largely redundant between requests, and eliminating duplicate information shaves off a non-trivial number of TCP round trips.


### Downsides and Myths

SPDY is actually slower than plain-old HTTP
: False. There is virtually no real-world evidence suggesting that SPDY is ineffective. A number of benchmarks have appeared that show SPDY to be slower across the board, though this can be attributed to a number of flaws in the benchmarks:

  - Testing in low-latency, high-bandwidth local connections rather than over the internet
  - Sharding SPDY connections across domains (as mentioned previously, domain sharding hurts SPDY performance)
  - Using a SPDY proxy rather than running a server that delivers content directly
  - Comparing benchmark data from a SPDY mirror of a website to the website itself rather than a HTTP(S) mirror of the website

  It *is* possible for non-SPDY requests to load faster when executed in parallel than the same requests made over a SPDY connection, but only on very fast network connections with low latency. Even if such a situation were to occur, the difference between SPDY and non-SPDY load times would be trivial.

SPDY doesn't work on sites that pull in third-party content
: Partly false. SPDY doesn't work across domains unless the domains share the same IP address. Third party content doesn't (usually) live on the same address as first party content, meaning that SPDY connections are simply not used for third party content (unless of course the third party host uses SPDY).

SPDY is hard to configure
: This is indeed something of a downside. For many developers, even setting up HTTPS properly and making sure it stays properly configured and up-to-date can be a real challenge. Implementing SPDY alongside that configuration doesn't make the challenge any easier.

SPDY isn't supported in IE
: This is essentially true. Only version 3 of SPDY is supported by Internet Explorer, and even then only when running on Windows 8. This is because only Windows 8 supports the TLS extension (NPN) needed to signal that the client can use SPDY.


### How to set it up

There are many ways to get SPDY up and running, but the most common way is to use Nginx. This short setup guide assumes that you already have SSL in place

First, make sure you have OpenSSL 1.0.1 or higher installed:

```bash
apt-get update
apt-get install build-essential libssl-dev libpcre3 libpcre3-dev
```

Next, download and install Nginx. At the time of writing, the latest stable version of Nginx is 1.6.0. You may wish to visit http://nginx.org to find the most current stable version.

W> #### Warning!
W>
W> If you have Nginx already installed on your server, following these instructions will remove it and may not preserve your configuration. This is because (at the time of writing) no popular software repositories have versions of Nginx configured to run SPDY. If you follow these instructions, be sure to back up your `nginx.conf` and any other custom configuration files you might have.


```bash
cd /tmp

# Download and unpack nginx
wget http://nginx.org/download/nginx-1.6.0.tar.gz
tar xvf nginx-1.6.0.tar.gz

cd nginx-1.6.0
# Configure nginx to use SPDY
./configure --with-http_spdy_module --with-http_ssl_module
# Note that you may need to pass additional config parameters
# if you require additional functionality.

# Remove existing nginx installations
dpkg -l | grep nginx
apt-get remove nginx-full nginx-common

make
make install
```

At this point, Nginx should be installed but not configured to your site. If you had a previous version of Nginx installed, restore your old configuration files. Make sure SSL is set up correctly using the setup guide in previous sections. Once you've completed that, setting up SPDY is simple. Just update your configuration to replace this:

```nginx
listen          443 ssl;
server_name     example.com;
```

with the following:

```nginx
listen          443 ssl spdy;  # Add SPDY
server_name     example.com;
spdy_headers_comp   5;  # Turn on SPDY header compression
```

Finally, restart Nginx with

```bash
/usr/local/nginx/sbin/nginx -s reload
```

That's it!


### QUIC

QUIC is another project by Google to eventually become the successor to SPDY. It is currently in a highly experimental state. Unlike SPDY, QUIC uses UDP rather than TCP, enabling content to be received in a truly asynchronous manner and eliminating blockages caused by a single slow packet. QUIC also seeks to decrease the number of round trips made to and from the server, and eliminate most--if not all--of the time required to establish a connection.

QUIC is currently implemented in Chrome and Opera and can be enabled by visiting `chrome://flags` and `opera://flags` respectively. Most Google properties support QUIC, and a reference implementation of the QUIC server has been published in the Chromium source code repository.
